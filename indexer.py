import os
import requests
from pathlib import Path
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from tqdm import tqdm

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
KNOWLEDGE_BASE_DIR = "knowledge_base"
ML_BACKEND_URL = "http://localhost:8000"
QDRANT_URL = "http://localhost:6333"
COLLECTION_NAME = "knowledge_base"
MODEL_NAME = "paraphrase-multilingual-mpnet-base-v2"
VECTOR_DIM = 768  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è mpnet-base-v2

# –í–ê–ñ–ù–û: –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
os.environ['NO_PROXY'] = 'localhost,127.0.0.1,0.0.0.0,::1'
os.environ['no_proxy'] = 'localhost,127.0.0.1,0.0.0.0,::1'

# –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –ë–ï–ó –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
local_session = requests.Session()
local_session.trust_env = False  # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–∫—Å–∏

def get_embedding(text: str) -> list:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ ML backend"""
    response = local_session.post(
        f"{ML_BACKEND_URL}/text_embed",
        json={"text": text, "model_name": MODEL_NAME}
    )
    response.raise_for_status()
    return response.json()["embedding"]

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> list:
    """–†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
    words = text.split()
    chunks = []
    
    for i in range(0, len(words), chunk_size - overlap):
        chunk_words = words[i:i + chunk_size]
        chunk = " ".join(chunk_words)
        if chunk.strip():
            chunks.append(chunk)
    
    return chunks if chunks else [text]

def read_knowledge_base():
    """–ü—Ä–æ—á–∏—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã content.txt –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    documents = []
    kb_path = Path(KNOWLEDGE_BASE_DIR)
    
    if not kb_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {KNOWLEDGE_BASE_DIR} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return documents
    
    # –ò—â–µ–º –≤—Å–µ content.txt —Ñ–∞–π–ª—ã
    content_files = list(kb_path.rglob("content.txt"))
    
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(content_files)}")
    
    for file_path in content_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            if not content:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —É—Ä–æ–∫–∞
            parts = file_path.parts
            category = parts[-3] if len(parts) >= 3 else "unknown"
            lesson = parts[-2] if len(parts) >= 2 else "unknown"
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
            chunks = chunk_text(content)
            
            for idx, chunk in enumerate(chunks):
                documents.append({
                    "text": chunk,
                    "category": category,
                    "lesson": lesson,
                    "file_path": str(file_path),
                    "chunk_id": idx,
                    "total_chunks": len(chunks)
                })
        
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file_path}: {e}")
    
    return documents

def create_collection(client: QdrantClient):
    """–°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤ Qdrant"""
    try:
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        client.delete_collection(collection_name=COLLECTION_NAME)
        print(f"üóëÔ∏è –°—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' —É–¥–∞–ª–µ–Ω–∞")
    except Exception as e:
        print(f"‚ÑπÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞: {e}")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
    client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=VECTOR_DIM, distance=Distance.COSINE)
    )
    print(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' —Å–æ–∑–¥–∞–Ω–∞")

def index_documents(documents: list):
    """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ Qdrant"""
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant
    client = QdrantClient(
        host="localhost",
        port=6333,
        timeout=60,
        prefer_grpc=False  # –¢–æ–ª—å–∫–æ REST API
    )
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    create_collection(client)
    
    print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é {len(documents)} —á–∞–Ω–∫–æ–≤...")
    
    points = []
    
    for idx, doc in enumerate(tqdm(documents, desc="–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")):
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = get_embedding(doc["text"])
            
            # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É –¥–ª—è Qdrant
            point = PointStruct(
                id=idx,
                vector=embedding,
                payload={
                    "text": doc["text"],
                    "category": doc["category"],
                    "lesson": doc["lesson"],
                    "file_path": doc["file_path"],
                    "chunk_id": doc["chunk_id"],
                    "total_chunks": doc["total_chunks"]
                }
            )
            points.append(point)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á–∞–º–∏ –ø–æ 100
            if len(points) >= 100:
                client.upsert(collection_name=COLLECTION_NAME, points=points)
                points = []
        
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {idx}: {e}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å—Ç–∞—Ç–∫–∏
    if points:
        client.upsert(collection_name=COLLECTION_NAME, points=points)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    collection_info = client.get_collection(collection_name=COLLECTION_NAME)
    print(f"\n‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –í—Å–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {collection_info.points_count}")

def main():
    print("=" * 60)
    print("üöÄ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–æ–≤
    try:
        local_session.get(f"{ML_BACKEND_URL}/docs", timeout=2)
        print(f"‚úÖ ML Backend –¥–æ—Å—Ç—É–ø–µ–Ω: {ML_BACKEND_URL}")
    except Exception as e:
        print(f"‚ùå ML Backend –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {ML_BACKEND_URL}")
        print(f"   –û—à–∏–±–∫–∞: {e}")
        return
    
    try:
        # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ REST API –Ω–∞–ø—Ä—è–º—É—é
        response = local_session.get(f"{QDRANT_URL}/collections", timeout=5)
        if response.status_code == 200:
            print(f"‚úÖ Qdrant –¥–æ—Å—Ç—É–ø–µ–Ω: {QDRANT_URL}")
        else:
            raise Exception(f"HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {QDRANT_URL}")
        print(f"   –û—à–∏–±–∫–∞: {e}")
        return
    
    # –ß–∏—Ç–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    documents = read_knowledge_base()
    
    if not documents:
        print("‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    print(f"\nüìù –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(documents)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = {}
    for doc in documents:
        cat = doc["category"]
        categories[cat] = categories.get(cat, 0) + 1
    
    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat, count in categories.items():
        print(f"   {cat}: {count} —á–∞–Ω–∫–æ–≤")
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
    print()
    index_documents(documents)
    
    print("\nüéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å RAG —Å–µ—Ä–≤–µ—Ä.")

if __name__ == "__main__":
    main()
